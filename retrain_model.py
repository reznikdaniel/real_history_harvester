import pandas as pd
import numpy as np
import joblib
from tensorflow.keras.models import load_model
import os

print("üß† –ó–∞–ø—É—Å–∫ MLOps Pipeline: Continuous Training")

FILE_NAME = "real_ground_history.csv"
MODEL_NAME = "forecast_ai_model.h5"
SCALER_NAME = "forecast_scaler.pkl"

def retrain():
    if not os.path.exists(FILE_NAME) or os.path.getsize(FILE_NAME) == 0:
        print("‚ùå Data Lake –ø–æ—Ä–æ–∂–Ω—ñ–π. –ù–µ–º–∞—î –Ω–∞ —á–æ–º—É –≤—á–∏—Ç–∏—Å—è.")
        return
        
    print("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –û–∑–µ—Ä–∞...")
    df = pd.read_csv(FILE_NAME)
    df['time'] = pd.to_datetime(df['time'])
    
    print("‚öôÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å–Ω—É—é—á–æ—ó –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ —Ç–∞ —Å–∫–µ–π–ª–µ—Ä–∞...")
    try:
        model = load_model(MODEL_NAME, compile=True) # compile=True –≤–∞–∂–ª–∏–≤–æ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
        scaler = joblib.load(SCALER_NAME)
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {e}")
        return

    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö (–Ω–∞—Ä—ñ–∑–∫–∞ –Ω–∞ –≤—ñ–∫–Ω–∞ 24->2)
    X_train, y_train = [], []
    
    # –ì—Ä—É–ø—É—î–º–æ –ø–æ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º —Å—Ç–∞–Ω—Ü—ñ—è–º, —â–æ–± –Ω–µ –∑–º—ñ—à—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ —Ä—ñ–∑–Ω–∏—Ö –º—ñ—Å—Ç
    for uid, group in df.groupby('uid'):
        group = group.sort_values('time')
        values = group[['pm2.5', 'pm10', 'no2']].values
        
        # –ù–∞–º —Ç—Ä–µ–±–∞ –º—ñ–Ω—ñ–º—É–º 26 –≥–æ–¥–∏–Ω (24 —ñ—Å—Ç–æ—Ä—ñ—è + 2 –ø—Ä–æ–≥–Ω–æ–∑)
        if len(values) < 26:
            continue
            
        # –ú–∞—Å—à—Ç–∞–±—É—î–º–æ –¥–∞–Ω—ñ —Ç–∏–º —Å–∞–º–∏–º —Å–∫–µ–π–ª–µ—Ä–æ–º
        scaled_values = scaler.transform(values)
        
        for i in range(len(scaled_values) - 25):
            # –í—Ö—ñ–¥: 24 –≥–æ–¥–∏–Ω–∏
            X_train.append(scaled_values[i:i+24])
            
            # –í–∏—Ö—ñ–¥: 4 –∑–Ω–∞—á–µ–Ω–Ω—è (pm2.5_1h, pm10_1h, pm2.5_2h, pm10_2h)
            y_train.append([
                scaled_values[i+24, 0], # pm2.5 —á–µ—Ä–µ–∑ 1 –≥–æ–¥–∏–Ω—É
                scaled_values[i+24, 1], # pm10 —á–µ—Ä–µ–∑ 1 –≥–æ–¥–∏–Ω—É
                scaled_values[i+25, 0], # pm2.5 —á–µ—Ä–µ–∑ 2 –≥–æ–¥–∏–Ω–∏
                scaled_values[i+25, 1]  # pm10 —á–µ—Ä–µ–∑ 2 –≥–æ–¥–∏–Ω–∏
            ])

    if not X_train:
        print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –±–µ–∑–ø–µ—Ä–µ—Ä–≤–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è (–ø–æ—Ç—Ä—ñ–±–Ω–æ –±—ñ–ª—å—à–µ —á–∞—Å—É –∑–±–æ—Ä—É).")
        return

    X_train = np.array(X_train)
    y_train = np.array(y_train)
    
    print(f"üéì –ü–æ—á–∏–Ω–∞—é –¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è –Ω–∞ {len(X_train)} –Ω–æ–≤–∏—Ö –ø–∞—Ç–µ—Ä–Ω–∞—Ö...")
    
    # –î–æ–æ–±—É—á–∞—î–º–æ –º–æ–¥–µ–ª—å (epochs=3 –¥–æ—Å—Ç–∞—Ç–Ω—å–æ, —â–æ–± –Ω–µ –∑–∞–±—É—Ç–∏ —Å—Ç–∞—Ä–µ, –∞–ª–µ –≤–∏–≤—á–∏—Ç–∏ –Ω–æ–≤–µ)
    model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=1)
    
    print("üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø–æ–∑—É–º–Ω—ñ—à–∞–ª–æ—ó –º–æ–¥–µ–ª—ñ...")
    model.save(MODEL_NAME)
    print("‚úÖ MLOps Pipeline —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    retrain()

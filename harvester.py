import requests
import pandas as pd
import time
from datetime import datetime
import os

print("üåç Big Data Harvester (–ì—ñ–±—Ä–∏–¥–Ω–∏–π —Ä–µ–∂–∏–º) –∑–∞–ø—É—â–µ–Ω–æ!")

API_TOKEN = "89bb553f1a69e42b0a03af6dd05c6b3a26aa2a70"
FILE_NAME = "real_ground_history.csv"

# –®–∏—Ä–æ–∫–∏–π –∫–≤–∞–¥—Ä–∞—Ç –¥–ª—è —Å—É—Å—ñ–¥—ñ–≤
BOUNDS = "43.0,20.0,54.0,40.0"

# –ü—Ä–∏–º—É—Å–æ–≤–∏–π –ø–æ—à—É–∫ –¥–ª—è –£–∫—Ä–∞—ó–Ω–∏ (—â–æ–± –æ–±—ñ–π—Ç–∏ –ª—ñ–º—ñ—Ç–∏ API)
UKRAINE_CITIES = ["Ukraine", "Kyiv", "Odesa", "Izmail", "Lviv", "Dnipro", "Kharkiv", "Mykolaiv", "Zaporizhzhia"]

# –§—ñ–ª—å—Ç—Ä –≤–æ—Ä–æ–∂–∏—Ö —Å—Ç–∞–Ω—Ü—ñ–π
BANNED_WORDS = ["Russia", "Belarus", "–†–§", "–ë–µ–ª–∞—Ä—É—Å—å", "Russian Federation", "Moscow"]

def fetch_and_save():
    new_data = []
    current_time = datetime.now().strftime('%Y-%m-%d %H:00:00')
    print(f"\n[{current_time}] üì° –§–æ—Ä–º—É–≤–∞–Ω–Ω—è —Å–ø–∏—Å–∫—É —Ü—ñ–ª–µ–π...")
    
    raw_stations = []
    
    # 1. –ó–∞–ø–∏—Ç –ø–æ –∫–≤–∞–¥—Ä–∞—Ç—É (–∑–∞–≥–∞–ª—å–Ω–∏–π)
    try:
        req1 = requests.get(f"https://api.waqi.info/map/bounds/?latlng={BOUNDS}&token={API_TOKEN}", timeout=10).json()
        if req1.get('status') == 'ok':
            raw_stations.extend(req1['data'])
    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ –∫–∞—Ä—Ç–∏: {e}")
        
    # 2. –ü—Ä–∏–º—É—Å–æ–≤—ñ —Ç–æ—á–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏ –ø–æ –£–∫—Ä–∞—ó–Ω—ñ
    for city in UKRAINE_CITIES:
        try:
            req2 = requests.get(f"https://api.waqi.info/search/?keyword={city}&token={API_TOKEN}", timeout=5).json()
            if req2.get('status') == 'ok':
                for s in req2['data']:
                    # –§–æ—Ä–º–∞—Ç –ø–æ—à—É–∫—É —Ç—Ä–æ—Ö–∏ –≤—ñ–¥—Ä—ñ–∑–Ω—è—î—Ç—å—Å—è –≤—ñ–¥ —Ñ–æ—Ä–º–∞—Ç—É –∫–∞—Ä—Ç–∏, —Ç–æ–º—É —É–Ω—ñ—Ñ—ñ–∫—É—î–º–æ
                    raw_stations.append({
                        'uid': s['uid'],
                        'station': {'name': s['station']['name']}
                    })
        except Exception as e:
            pass
        time.sleep(0.1) # –ü–∞—É–∑–∞ –ø—Ä–æ—Ç–∏ –±–∞–Ω—É
        
    # 3. –í–∏–¥–∞–ª–µ–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤ (–∑–∞ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º ID —Å—Ç–∞–Ω—Ü—ñ—ó)
    unique_stations = {}
    for s in raw_stations:
        unique_stations[s['uid']] = s
        
    stations_list = list(unique_stations.values())
    print(f"üéØ –ó–Ω–∞–π–¥–µ–Ω–æ {len(stations_list)} —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Å—Ç–∞–Ω—Ü—ñ–π. –ü–æ—á–∏–Ω–∞—é –¥–µ—Ç–∞–ª—å–Ω–∏–π –∑–±—ñ—Ä...")

    # 4. –ó–±—ñ—Ä –ø–æ–∫–∞–∑–Ω–∏–∫—ñ–≤ –ø–æ–≤—ñ—Ç—Ä—è
    for s in stations_list:
        uid = s['uid']
        name = s.get('station', {}).get('name', 'Unknown')
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –±–∞–Ω-–ª–∏—Å—Ç
        if any(banned.lower() in name.lower() for banned in BANNED_WORDS):
            continue
            
        try:
            details = requests.get(f"https://api.waqi.info/feed/@{uid}/?token={API_TOKEN}", timeout=5).json()
            
            if details.get('status') == 'ok':
                # üõ°Ô∏è –í–ê–ö–¶–ò–ù–ê –í–Ü–î –ó–û–ú–ë–Ü: –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–µ–∞–ª—å–Ω–∏–π —á–∞—Å —Å—Ç–∞–Ω—Ü—ñ—ó
                station_time_str = details['data'].get('time', {}).get('s')
                if station_time_str:
                    station_time = datetime.strptime(station_time_str, "%Y-%m-%d %H:%M:%S")
                    hours_dead = (datetime.now() - station_time).total_seconds() / 3600
                    if hours_dead > 12:
                        continue # –°—Ç–∞–Ω—Ü—ñ—è –º–µ—Ä—Ç–≤–∞, —ñ–≥–Ω–æ—Ä—É—î–º–æ —ó—ó —ñ –π–¥–µ–º–æ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ—ó
                        
                iaqi = details['data'].get('iaqi', {})
                pm25 = float(iaqi.get('pm25', {}).get('v', 0))
                pm10 = float(iaqi.get('pm10', {}).get('v', 0))
                no2 = float(iaqi.get('no2', {}).get('v', 0))
                
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ª–∏—à–µ "–∂–∏–≤—ñ" —Å—Ç–∞–Ω—Ü—ñ—ó
                if pm25 > 0 or pm10 > 0:
                    new_data.append({
                        'time': current_time,
                        'station': name,
                        'uid': uid,
                        'pm2.5': pm25,
                        'pm10': pm10,
                        'no2': no2
                    })
        except Exception as e:
            pass 
        
        time.sleep(0.1)

    # 5. –ó–∞–ø–∏—Å —É Data Lake
    if new_data:
        df_new = pd.DataFrame(new_data)
        
        if os.path.exists(FILE_NAME) and os.path.getsize(FILE_NAME) > 0:
            try:
                df_existing = pd.read_csv(FILE_NAME)
                df_combined = pd.concat([df_existing, df_new]).drop_duplicates(subset=['time', 'uid'], keep='last')
                df_combined.to_csv(FILE_NAME, index=False)
            except pd.errors.EmptyDataError:
                df_new.to_csv(FILE_NAME, index=False)
        else:
            df_new.to_csv(FILE_NAME, index=False)
        
        print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(new_data)} –∑–∞–ø–∏—Å—ñ–≤. –ú—ñ—Å—ñ—è –≤–∏–∫–æ–Ω–∞–Ω–∞.")

if __name__ == "__main__":
    fetch_and_save()

